{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inWidth=368\n",
    "inHeight=368\n",
    "thr=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, Button, Layout, HBox, FileUpload, VBox\n",
    "import os\n",
    "\n",
    "# Assuming BODY_PARTS, POSE_PAIRS, inWidth, inHeight, thr, and graph_opt.pb are defined elsewhere\n",
    "\n",
    "# Function to calculate pose similarity\n",
    "def calculate_pose_similarity(points1, points2):\n",
    "    # Implement your pose similarity calculation logic here\n",
    "    # This can be based on Euclidean distance between corresponding body parts, angles, etc.\n",
    "    # Return a similarity score between 0 (different) and 1 (similar)\n",
    "\n",
    "    # Example: Euclidean distance between corresponding body parts\n",
    "    distances = [np.linalg.norm(np.array(p1) - np.array(p2)) if (p1 is not None and p2 is not None) else 0\n",
    "                 for p1, p2 in zip(points1, points2)]\n",
    "\n",
    "    # Normalize distances and calculate similarity score\n",
    "    max_distance = np.sqrt(2 * (800**2))  # Max possible distance in an 800x800 frame\n",
    "    similarity_score = 1 - (sum(distances) / (len(distances) * max_distance))\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "# Load the pose estimation model from graph_opt.pb\n",
    "net = cv2.dnn.readNetFromTensorflow('graph_opt.pb')\n",
    "\n",
    "# Define the folder path to store the pose images\n",
    "poses_folder = 'C:\\\\Users\\\\hp\\\\Poses'\n",
    "\n",
    "# Get the list of existing pose images\n",
    "existing_poses = [f for f in os.listdir(poses_folder) if f.endswith('.jpg')]\n",
    "\n",
    "# Create buttons and set an initial value for selected_pose_path\n",
    "button_layout = Layout(width='50px', height='50px')\n",
    "buttons = []\n",
    "button_images = []\n",
    "\n",
    "def start_pose_comparison(b):\n",
    "    global selected_pose_path\n",
    "    selected_pose_path = os.path.join(poses_folder, existing_poses[buttons.index(b)])\n",
    "    print(f\"Selected Pose Path: {selected_pose_path}\")\n",
    "\n",
    "# Create buttons and display them\n",
    "for pose in existing_poses:\n",
    "    img_path = os.path.join(poses_folder, pose)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (50, 50))\n",
    "    img_widget = widgets.Image(value=cv2.imencode('.png', img)[1].tobytes(), format='png', width=50, height=50)\n",
    "    button_images.append(img_widget)\n",
    "    button = Button(description='', layout=button_layout, image=img_widget)\n",
    "    button.on_click(start_pose_comparison)\n",
    "    buttons.append(button)\n",
    "\n",
    "# Set initial value for selected_pose_path\n",
    "selected_pose_path = os.path.join(poses_folder, existing_poses[0])\n",
    "\n",
    "# Create a FileUpload widget for uploading new poses\n",
    "upload_pose_widget = FileUpload(accept='image/*', multiple=True)\n",
    "\n",
    "# Function to handle the file upload\n",
    "def handle_upload(change):\n",
    "    global selected_pose_path\n",
    "    uploaded_files = upload_pose_widget.value\n",
    "    for filename, file_info in uploaded_files.items():\n",
    "        img_path = os.path.join(poses_folder, filename)\n",
    "        with open(img_path, 'wb') as f:\n",
    "            f.write(file_info['content'])\n",
    "        # Update the selected_pose_path with the newly uploaded photo\n",
    "        selected_pose_path = img_path\n",
    "        # Add the new pose to the list of existing poses and update the buttons\n",
    "        existing_poses.append(filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (50, 50))\n",
    "        img_widget = widgets.Image(value=cv2.imencode('.png', img)[1].tobytes(), format='png', width=50, height=50)\n",
    "        button = Button(description='', layout=button_layout, image=img_widget)\n",
    "        button.on_click(start_pose_comparison)\n",
    "        buttons.append(button)\n",
    "        button_images.append(img_widget)\n",
    "        print(f\"Uploaded Pose: {img_path}\")\n",
    "\n",
    "# Attach the handle_upload function to the file upload widget\n",
    "upload_pose_widget.observe(handle_upload, names='value')\n",
    "\n",
    "# Display buttons and upload widget\n",
    "button_row = HBox(buttons)\n",
    "image_row = HBox(button_images)\n",
    "display(button_row, image_row, upload_pose_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the selected_pose_path variable is already defined in the first cell\n",
    "\n",
    "# Capture video from the live camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 800)\n",
    "cap.set(4, 800)\n",
    "\n",
    "warning_messages = {\n",
    "    BODY_PARTS['LWrist']: \"Adjust your left wrist and arm\",\n",
    "    BODY_PARTS['RWrist']: \"Adjust your right wrist and arm\",\n",
    "    BODY_PARTS['LAnkle']: \"Adjust your left leg and ankle\",\n",
    "    BODY_PARTS['RAnkle']: \"Adjust your right leg and ankle\",\n",
    "    BODY_PARTS['Neck']: \"Adjust your head and neck\",\n",
    "}\n",
    "\n",
    "# Main loop for live video comparison\n",
    "while cv2.waitKey(1) < 0:\n",
    "    has_frame, frame = cap.read()\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "\n",
    "    # Resize the live frame to match the height of the selected pose image\n",
    "    frame_resized = cv2.resize(frame, (400, 800))\n",
    "\n",
    "    # Perform pose estimation on the live frame\n",
    "    net.setInput(cv2.dnn.blobFromImage(frame_resized, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out_live = net.forward()\n",
    "    out_live = out_live[:, :19, :, :]\n",
    "\n",
    "    points_live = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        heatMap = out_live[0, i, :, :]\n",
    "        _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "        x = (400 * point[0]) / out_live.shape[3]\n",
    "        y = (800 * point[1]) / out_live.shape[2]\n",
    "        points_live.append((int(x), int(y)) if conf > thr else None)\n",
    "\n",
    "    # Perform pose estimation on the selected pose image\n",
    "    pose_img = cv2.imread(selected_pose_path)\n",
    "    pose_img = cv2.resize(pose_img, (800, 800))\n",
    "\n",
    "    net.setInput(cv2.dnn.blobFromImage(pose_img, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out_pose = net.forward()\n",
    "    out_pose = out_pose[:, :19, :, :]\n",
    "\n",
    "    assert(len(BODY_PARTS) == out_pose.shape[1])\n",
    "\n",
    "    points_pose = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        heatMap = out_pose[0, i, :, :]\n",
    "        _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "        x = (800 * point[0]) / out_pose.shape[3]\n",
    "        y = (800 * point[1]) / out_pose.shape[2]\n",
    "        points_pose.append((int(x), int(y)) if conf > thr else None)\n",
    "\n",
    "    # Compare poses and calculate similarity score\n",
    "    similarity_score = calculate_pose_similarity(points_pose, points_live)\n",
    "\n",
    "    # Draw the expected pose on the live frame\n",
    "    frame_resized_with_pose = pose_img.copy()\n",
    "\n",
    "    for pair in POSE_PAIRS:\n",
    "        part_from = pair[0]\n",
    "        part_to = pair[1]\n",
    "        assert(part_from in BODY_PARTS)\n",
    "        assert(part_to in BODY_PARTS)\n",
    "\n",
    "        id_from = BODY_PARTS[part_from]\n",
    "        id_to = BODY_PARTS[part_to]\n",
    "\n",
    "        if points_pose[id_from] and points_pose[id_to]:\n",
    "            cv2.line(frame_resized_with_pose, points_pose[id_from], points_pose[id_to], (0, 255, 0), 3)\n",
    "            cv2.ellipse(frame_resized_with_pose, points_pose[id_from], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.ellipse(frame_resized_with_pose, points_pose[id_to], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "    # Draw the live pose on the live frame\n",
    "    for pair in POSE_PAIRS:\n",
    "        part_from = pair[0]\n",
    "        part_to = pair[1]\n",
    "        assert(part_from in BODY_PARTS)\n",
    "        assert(part_to in BODY_PARTS)\n",
    "\n",
    "        id_from = BODY_PARTS[part_from]\n",
    "        id_to = BODY_PARTS[part_to]\n",
    "\n",
    "        if points_live[id_from] and points_live[id_to]:\n",
    "            cv2.line(frame_resized, points_live[id_from], points_live[id_to], (0, 255, 0), 3)\n",
    "            cv2.ellipse(frame_resized, points_live[id_from], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.ellipse(frame_resized, points_live[id_to], (3, 3), 0, 0, 360, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "    # Display the live frame with the drawn expected and live poses\n",
    "    combined_frame = np.concatenate((frame_resized, frame_resized_with_pose), axis=1)\n",
    "\n",
    "    # Display instructions on the live frame\n",
    "    if similarity_score > 0.95:  # Adjust the threshold as needed\n",
    "        cv2.putText(combined_frame, \"Your pose is good!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        # Display warnings for detected issues\n",
    "        for part_id, warning_message in warning_messages.items():\n",
    "            if points_live[part_id] is None:\n",
    "                cv2.putText(combined_frame, warning_message, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                break  # Display only one warning at a time\n",
    "\n",
    "    # Display the live frame in another window\n",
    "    cv2.imshow('Live Pose Comparison', combined_frame)\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
